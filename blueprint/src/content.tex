% In this file you should put the actual content of the blueprint.
% It will be used both by the web and the print version.
% It should *not* include the \begin{document}
%
% If you want to split the blueprint content into several files then
% the current file can be a simple sequence of \input. Otherwise It
% can start with a \section or \chapter for instance.

\title{Bachman-Landau notation and the Master theorem for divide-and-conquer recurrences}

The primary goal of this project is to formalize some results from computational 
complexity theory in Lean 4:
\begin{itemize}
\item the Bachman-Landau family of notations, e.g. big O and other closely related notations,
\item properties of the Bachman-Landau notations,
\item the Master theorem for divide-and-conquer recurrences,
\item and, if time permits, the Akra-Bazzi method which solves a more general class of recurrences
\end{itemize}

\section{Basic asymptotic properties of functions}

\begin{definition}
    \label{def:asymp_pos}
    \lean{AsympPos}
    \leanok
    $f(x)$ is asymptotically positive if there exists $x_0$ such that $f(x) \ge 0$
    for all $x \ge x_0$.

\end{definition}

\begin{definition}
    \label{def:asymp_neg}
    \lean{AsympNeg}
    \leanok
    $f(x)$ is asymptotically negative if there exists $x_0$ such that $f(x) \le 0$
    for all $x \ge x_0$.

\end{definition}

\begin{definition}
    \label{def:asymp_le}
    \lean{AsympLE}
    \leanok
    $f(x)$ is asymptotically less than $g(x)$ if there exists $x_0$ such that
    $f(x) \le g(x)$ for all $x \ge x_0$.

\end{definition}

\begin{definition}
    \label{def:asymp_ge}
    \lean{AsympGE}
    \leanok
    $f(x)$ is asymptotically greater than $g(x)$ if there exists $x_0$ such that
    $f(x) \ge g(x)$ for all $x \ge x_0$.

\end{definition}


\subsection{Positivity and negativity}

\begin{lemma}
    \label{lemma:asymp_neg_of_pos}
    \lean{asymp_neg_of_pos}
    \leanok
    \uses{def:asymp_pos, def:asymp_neg}
    If $f(x)$ is asymptotically negative, then $-f(x)$ is asymptotically positive.
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_pos_of_neg}
    \lean{asymp_pos_of_neg}
    \leanok
    \uses{def:asymp_pos, def:asymp_neg}
    If $f(x)$ is asymptotically positive, then $-f(x)$ is asymptotically negative.
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}


\subsection{Reflexivity}

\begin{lemma}
    \label{lemma:asymp_le_refl}
    \lean{asymp_le_refl}
    \leanok
    \uses{def:asymp_le}
    $f(x)$ is asymptotically less than $f(x)$.
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_ge_refl}
    \lean{asymp_ge_refl}
    \leanok
    \uses{def:asymp_ge}
    $f(x)$ is asymptotically greater than $f(x)$.
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_le_of_ge}
    \lean{asymp_le_of_ge}
    \leanok
    \uses{def:asymp_le, def:asymp_ge}
    TODO

\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}


\subsection{Equivalence}

\begin{lemma}
    \label{lemma:asymp_ge_of_le}
    \lean{asymp_ge_of_le}
    \leanok
    \uses{def:asymp_le, def:asymp_ge}
    TODO

\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_le_ge_iff}
    \lean{asymp_le_ge_iff}
    \leanok
    \uses{def:asymp_le, def:asymp_ge}
    TODO

\end{lemma}

\begin{proof}
    \leanok
    \uses{lemma:asymp_le_of_ge, lemma:asymp_ge_of_le}
    TODO
\end{proof}


\subsection{Additivity}

\begin{lemma}
    \label{lemma:asymp_le_add}
    \lean{asymp_le_add}
    \leanok
    \uses{def:asymp_le}
    TODO
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_ge_add}
    \lean{asymp_ge_add}
    \leanok
    \uses{def:asymp_ge}
    TODO
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_ge_add_pos}
    \lean{asymp_ge_add_pos}
    \leanok
    \uses{def:asymp_ge}
    TODO
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{lemma}
    \label{lemma:asymp_le_add_neg}
    \lean{asymp_le_add_neg}
    \leanok
    \uses{def:asymp_ge}
    TODO
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}


\subsection{Scalar multiplicativity}

\begin{theorem}
    \label{thm:asymp_le_pos_mul}
    \lean{asymp_le_pos_mul}
    \leanok
    \uses{def:asymp_le}
    TODO
\end{theorem}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{theorem}
    \label{thm:asymp_ge_pos_mul}
    \lean{asymp_ge_pos_mul}
    \leanok
    \uses{def:asymp_ge}
    TODO
\end{theorem}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{theorem}
    \label{thm:asymp_le_neg_mul}
    \lean{asymp_le_neg_mul}
    \leanok
    \uses{def:asymp_le}
    TODO
\end{theorem}

\begin{proof}
    \leanok
    TODO
\end{proof}

\begin{theorem}
    \label{thm:asymp_ge_neg_mul}
    \lean{asymp_ge_pos_mul}
    \leanok
    \uses{def:asymp_ge}
    TODO
\end{theorem}

\begin{proof}
    \leanok
    TODO
\end{proof}


\section{Asymptotic growth}

\begin{definition}
    \label{def:asymp_bounded_above}
    \lean{AsympBoundedAbove}
    \leanok
    \uses{def:asymp_le}
    $f(x)$ is asymptotically bounded above by $g(x)$ if there exists a $k > 0$ 
    such that $f(x)$ is asymptotically less than $k*g(x)$.
\end{definition}

\begin{definition}
    \label{def:asymp_bounded_below}
    \lean{AsympBoundedBelow}
    \leanok
    \uses{def:asymp_ge}
    $f(x)$ is asymptotically bounded below by $g(x)$ if there exists $k > 0$ 
    such that $f(x)$ is asymptotically greater than $k*g(x)$.
\end{definition}

\begin{definition}
    \label{def:asymp_bounded}
    \lean{AsympBounded}
    \leanok
    \uses{def:asymp_bounded_above, def:asymp_bounded_below}
    $f(x)$ is asymptotically bounded by $g(x)$ if $f(x)$ is asymptotically bounded
    above and below by $g(x)$.
\end{definition}

\begin{definition}
    \label{def:asymp_right_dom}
    \lean{AsympRightDom}
    \leanok
    \uses{def:asymp_le}
    $f(x)$ is asymptotically dominated by $g(x)$ if for all $k > 0$ $f(x)$ is asymptotically 
    less than $k*g(x)$.

\end{definition}

\begin{definition}
    \label{def:asymp_left_dom}
    \lean{AsympLeftDom}
    \leanok
    \uses{def:asymp_ge}
    $f(x)$ asymptotically dominates $g(x)$ if for all $k > 0$ $(x)$ is asymptotically
    greater than $k*g(x)$.

\end{definition}

\begin{lemma}
    \label{lemma:asymp_right_dom_imp_bounded_above}
    \lean{asymp_right_dom_imp_bounded_above}
    \leanok
    \uses{def:asymp_right_dom, def:asymp_bounded_above}
    If $f(x)$ is dominated by $g(x)$, then it's also bounded above by $g(x)$.
\end{lemma}

\begin{proof}
    \leanok 
    The definitions of $f(x)$ being dominated and bounded above by $g(x)$ only differ
    in the quantifier before $k$ at the very start (universal for the former, existential
    for the latter), so it suffices to use any positive value for $k$. We use $1$. 
    The desired result then follows directly.
\end{proof}

\begin{lemma}
    \label{lemma:asymp_left_dom_imp_bounded_below}
    \lean{asymp_left_dom_imp_bounded_below}
    \leanok
    \uses{def:asymp_left_dom, def:asymp_bounded_below}
    If $f(x)$ dominates $g(x)$, then it's bounded below by $g(x)$.
\end{lemma}

\begin{proof}
    \leanok
    The proof is entirely analogous to the proof of Theorem 
    \ref{lemma:asymp_right_dom_imp_bounded_above}, again using the value 
    $1$ for $k$.
\end{proof}
\begin{theorem}
    \label{thm:asymp_bounded_above_below_iff}
    \lean{asymp_bounded_above_below_iff}
    \leanok
    \uses{def:asymp_bounded_above, def:asymp_bounded_below, def:asymp_bounded}
    If $f(x)$ is bounded above and below by $g(x)$, then it's bounded by $g(x)$.
\end{theorem}

\begin{proof}
    \leanok
    First, assume $f(x)$ is bounded above and below by $g(x)$. There is a constant
    $k\_1 > 0$ such that $|f(x)| \le k\_1 |g(x)|$ for all $x > x\_0$ for some $x\_0$.
    Analogously, there is a constant $k\_2 > 0$ such that $|f(x)| \ge k\_2 |g(x)|$ 
    for all $x > x\_1$ for some $x\_1$. For $f(x)$ to be properly bounded by $g(x)$ 
    we need a single constant $x\_2$ - we take $x\_2 = \max{\{x\_1, x\_2\}}$. Since 
    $x\_2 \ge x\_0$ and $x\_2 \ge x\_1$, we have $|f(x) \le k\_1 |g(x)|$ and 
    $|f(x)| \ge k\_2 |g(x)|$ for all $x > x\_2$, which means that $f(x)$ is bounded
    by $g(x)$.

    Conversely, assume $f(x)$ is bounded by $g(x)$.
\end{proof}

\begin{lemma}
    \label{thm:asymp_bounded_below_imp_not_right_dom}
    \lean{pos_asymp_bounded_below_imp_not_right_dom}
    \leanok
    \uses{def:asymp_pos, def:asymp_bounded_above, def:asymp_right_dom}
    Let $f(x)$ be asymptotically positive. If $f(x)$ is bounded below by $g(x)$, then $f(x)$ 
    is not dominated by $g(x)$.
\end{lemma}

\begin{proof}
    TODO 
\end{proof}

\begin{lemma}
    \label{thm:asymp_bounded_above_imp_not_left_dom}
    \lean{pos_asymp_bounded_above_imp_not_left_dom}
    \leanok
    \uses{def:asymp_pos, def:asymp_bounded_below, def:asymp_left_dom}
    Let $f(x)$ be asymptotically positive. If $f(x)$ is bounded below by $g(x)$, then $f(x)$ 
    does not dominate $g(x)$.
\end{lemma}

\begin{proof}
    TODO 
\end{proof}


\section{Bachman-Landau notation}

Bachman-Landau family of notations is the name of a few closely related notations used in 
algorithm analysis. The most famous of them is the so-called big-O notation. While
most formulations are defined on functions from naturals or reals to reals, we define 
them more generally - requirements for the types of the domain and codomain vary between 
different properties. However, all properties hold for functions from a linearly ordered 
commutative ring to a linearly ordered field. In the rest of this page, we let $R$ be a linearly 
ordered commutative ring and $F$ be a linearly ordered field. We will also use symbols $f$, 
$f\_1$, $f\_2$, $g$, $g\_1$ and $g\_2$ for functions $R \to F$. Also, we let $M$ be 
a right $R$-module, which often has to only be a (distributive) left multiplicative action
on $R$.


\subsection{Asymptotic sets}

\begin{definition}(Big O notation)
    \label{def:big_o}
    \lean{O}
    \leanok
    \uses{def:asymp_bounded_above}
    $f(x) \in O(g(x))$ if it is asymptotically bounded above by $g(x)$.
\end{definition}

\begin{definition}(Big Omega notation)
    \label{def:big_omega}
    \lean{Ω}
    \leanok
    \uses{def:asymp_bounded_below}
    $f(x) \in \Omega(g(x))$ if it is asymptotically bounded below by $g(x)$.
\end{definition}

\begin{definition}(Big Theta notation)
    \label{def:big_theta}
    \lean{Θ}
    \leanok
    \uses{def:asymp_bounded}
    $f(x) \in \Theta(g(x))$ if it is asymptotically bounded by $g(x)$. 
\end{definition}

\begin{definition}(Small O notation)
    \label{def:small_o}
    \lean{o}
    \leanok
    \uses{def:asymp_right_dom}
    $f(x) \in o(g(x))$ if it is asymptotically dominated by $g(x)$.
\end{definition}

\begin{definition}(Small Omega notation)
    \label{def:small_omega}
    \lean{ω}
    \leanok
    \uses{def:asymp_left_dom}
    $f(x) \in \omega(g(x))$ if it asymptotically dominates $g(x)$.
\end{definition}


\subsection{Relations between asymptotic sets}

\begin{lemma}
    \label{lemma:small_o_imp_big_o}
    \lean{o_imp_O}
    \leanok
    \uses{def:small_o, def:big_o}
    If $f(x) \in o(g(x))$, then $f(x) \in O(f(x))$.
\end{lemma}

\begin{proof}
    \leanok
    \uses{lemma:asymp_dominated_imp_bounded_above}
    Since $o(g(x))$ and $O(f(x))$, we can simply use Theorem 
    \ref{lemma:asymp_right_dom_imp_bounded_above}.
\end{proof}

\begin{theorem}
    \label{thm:small_omega_imp_big_omega}
    \lean{ω_imp_Ω}
    \leanok
    \uses{def:small_omega, def:big_omega}
    If $f(x) \in \omega(g(x))$, then $f(x) \in \Omega(g(x))$.
\end{theorem}

\begin{proof}
    \leanok
    \uses{lemma:asymp_left_dom_imp_bounded_below}
    The proof is a simple application of Theorem 
    \ref{lemma:asymp_left_dom_imp_bounded_below}.
\end{proof}

\begin{theorem}
    \label{thm:big_o_and_omega_iff_theta}
    \lean{O_and_Ω_iff_Θ}
    \leanok
    \uses{def:big_o, def:big_omega, def:big_theta}
    $f(x) \in O(g(x))$ and $f(x) \in \Omega(g(x))$ if and only if $f(x) \in \Theta(g(x))$.
\end{theorem}

\begin{proof}
    \leanok
    \uses{thm:asymp_bounded_above_below_iff}
    Similarly to previous proofs, the proof is a direct application of Theorem 
    \ref{thm:asymp_bounded_above_below_iff_bounded}.
\end{proof}


\subsection{Properties of asymptotic growth}

\subsubsection{Reflexivity}

\begin{lemma}
    \label{lemma:asymp_bounded_refl}
    \lean{asymp_bounded_refl}
    \leanok
    \uses{def:asymp_bounded}
    $f(x)$ is asymptotically bounded by itself. 

\end{lemma}

\begin{proof}
    \leanok
    \uses{def:asymp_bounded, def:asymp_bounded_above, def:asymp_bounded_below}
    Proving asymptotic boundedness is equivalent to proving boundedness above and below.
    Both can be proved the same way - we choose $1_K$ for $K$ and $1_R$ for $N$, then the
    required asymptotic growth properties follow from definitions of identity elements for 
    $K$ and $R$.
\end{proof}

\begin{lemma}
    \label{lemma:asymp_bounded_above_refl}
    \lean{asymp_bounded_above_refl}
    \leanok
    \uses{def:asymp_bounded_above}
    $f(x)$ is asymptotically bounded above by itself.

\end{lemma}

\begin{proof}
    \leanok
    \uses{lemma:asymp_bounded_refl}
    This follows directly from \ref{lemma:asymp_bounded_refl}.
\end{proof}

\begin{lemma}
    \label{lemma:asymp_bounded_below_refl}
    \lean{asymp_bounded_below_refl}
    \leanok
    \uses{def:asymp_bounded_below}
    $f(x)$ is asymptotically bounded below by itself.

\end{lemma}

\begin{proof}
    \leanok
    \uses{lemma:asymp_bounded_refl}
    This follows directly from \ref{lemma:asymp_bounded_refl}.
\end{proof}


\subsubsection{Scalar multiplicativity}


\begin{lemma}
    \label{lemma:asymp_bounded_above_pos_smul}
    \lean{asymp_bounded_above_pos_smul}
    \leanok
    \uses{def:asymp_bounded_above}
    Let $c > 0$. If $f(x)$ is bounded above by $(gx)$, then $c*f(x)$ is also bounded
    above by $g(x)$.
\end{lemma}

\begin{proof}
    \leanok
    TODO
\end{proof}


\subsubsection{Additivity}


\section{The Master theorem}

Analyzing the time complexity of algorithms, especially recursive ones, is more often 
than not a non-trivial task. For a recursive algorithm, its time complexity can be 
written as a recurrence formula, which is generally not easy, sometimes even impossible 
to solve with a closed formula. In some cases, though, it turns out that we can find 
asymptotic bounds of the solution, despite not being able to necessarily find the 
precise solution to the recurrence. One class of such cases is the class of 
divide-and-conquer algorithms, i.e. algorithms that work by recursively splitting the input 
problem into similarly-sized subproblems. Those have especially nice recurrence formulas 
which can be asymptotically bounded with an elegant formula that is known as the Master theorem.

\begin{theorem}[Master theorem for divide-and-conquer recurrences]
TODO
\end{theorem}
